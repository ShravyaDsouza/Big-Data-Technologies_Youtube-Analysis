{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c601a2-8ce7-4bdb-9e01-d66bc7875451",
   "metadata": {},
   "source": [
    "# **Dataset Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de64c5-e68b-44aa-a87c-d77775bf696d",
   "metadata": {},
   "source": [
    "#### 1. Automated Process of Unzipping of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6e095-5ab6-4a4f-8b23-a6388f4ce9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e8361-f312-4c01-84f3-31a57ac2af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/path/to/youtube_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdaa274-d226-4f64-89a2-7c50e7324a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_files = [f for f in os.listdir(dataset_dir) if f.endswith('.zip')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b39692-f52f-4c85-971b-c0b87d6512a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip each file\n",
    "for zip_file in zip_files:\n",
    "    zip_path = os.path.join(dataset_dir, zip_file)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c2c71-2a89-4f71-90d8-3d5286ef82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_folders = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]\n",
    "if len(extracted_folders) == len(zip_files):\n",
    "    # Delete zip files if extraction is complete\n",
    "    for zip_file in zip_files:\n",
    "        os.remove(os.path.join(dataset_dir, zip_file))\n",
    "    print(\"All zip files extracted and deleted successfully.\")\n",
    "else:\n",
    "    print(\"Extraction verification failed. Zip files not deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e49922-2950-40fc-8189-272e5102de55",
   "metadata": {},
   "source": [
    "#### 2. Collecting Relevant Files , Renaming and Storing in a new folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33b665-ed44-4475-8c83-00aa4feae319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7a0d7-9090-4bf1-ab9a-dd4f6a623e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/path/to/youtube_dataset\"\n",
    "temp_dir = \"/path/to/youtube_dataset_temp\"\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3efe8-9d1c-4691-9cb7-eb89b302568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each folder in the dataset directory\n",
    "for folder_name in os.listdir(dataset_dir):\n",
    "    folder_path = os.path.join(dataset_dir, folder_name)\n",
    "    \n",
    "    # Ensure we're working with directories only\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.txt') and file_name != \"log.txt\":  # Omit \"log.txt\"\n",
    "                # Create a new unique filename with folder name as prefix\n",
    "                new_file_name = f\"{folder_name}_{file_name}\"\n",
    "                src_path = os.path.join(folder_path, file_name)\n",
    "                dest_path = os.path.join(temp_dir, new_file_name)\n",
    "                \n",
    "                # Copy file with the new name to the temp directory\n",
    "                shutil.copy(src_path, dest_path)\n",
    "                \n",
    "                # Print success message\n",
    "                print(f\"Successfully stored {new_file_name} from folder: {folder_name}\")\n",
    "\n",
    "print(\"All files processed and stored in youtube_dataset_temp.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48796858-5886-4865-97a5-e84679373330",
   "metadata": {},
   "source": [
    "# **Dataset Cleaning and Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b065c4-8155-4a39-bdf6-d5248189b25a",
   "metadata": {},
   "source": [
    "#### 1.Automated Script which would result in formatted_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec962754-90ea-4aa3-932a-ad89fa5be162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import split, col, array, expr\n",
    "from pyspark.sql import functions as F\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb9595-7cd0-4110-b67d-02cd5e86833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Merge, Validate, and Store YouTube Dataset\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897076b3-7fea-46e0-9479-75f8a7daf706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a schema with a single string column to load entire lines as single entries\n",
    "schema = StructType([\n",
    "    StructField(\"line\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f55693-650b-4d41-a134-15cab74379ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge all txt files from youtube_dataset_temp\n",
    "temp_dir = \"/oath/to/youtube_dataset_temp\"\n",
    "txt_files = glob.glob(f\"{temp_dir}/*.txt\")\n",
    "combined_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ceb750-c0b2-4b6d-bacd-8bed9155dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in txt_files:\n",
    "    df = spark.read.schema(schema).csv(f\"file://{os.path.abspath(file_path)}\")\n",
    "    combined_df = df if combined_df is None else combined_df.union(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2407b90-6d06-4904-815d-a4d410bede6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Displaying raw data content:\")\n",
    "combined_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af04e48-0b13-4b6d-8c9f-4e9dc7b4ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_cols = split(col(\"line\"), \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac7542-c624-43a2-a874-f55820a44f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define each expected column explicitly with handling for related IDs\n",
    "combined_df = combined_df.withColumn(\"video_id\", split_cols.getItem(0)) \\\n",
    "    .withColumn(\"uploader\", split_cols.getItem(1)) \\\n",
    "    .withColumn(\"age\", split_cols.getItem(2).cast(IntegerType())) \\\n",
    "    .withColumn(\"category\", split_cols.getItem(3)) \\\n",
    "    .withColumn(\"length\", split_cols.getItem(4).cast(IntegerType())) \\\n",
    "    .withColumn(\"views\", split_cols.getItem(5).cast(IntegerType())) \\\n",
    "    .withColumn(\"rate\", split_cols.getItem(6).cast(DoubleType())) \\\n",
    "    .withColumn(\"ratings\", split_cols.getItem(7).cast(IntegerType())) \\\n",
    "    .withColumn(\"comments\", split_cols.getItem(8).cast(IntegerType())) \\\n",
    "    .withColumn(\"related_ids\", array([split_cols.getItem(i) for i in range(9, 29)]))  # Capture all remaining as related_ids array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32761b-72ee-48ad-859e-9edb35850f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.drop(\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1892c-0b8d-4849-979c-0325fb07fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.withColumn(\"related_ids\", F.expr(\"concat_ws(',', related_ids)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e049fb-34a8-4d78-bd63-6ab9fd2bacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df \\\n",
    "    .withColumnRenamed(\"video_id\", \"Video ID\") \\\n",
    "    .withColumnRenamed(\"uploader\", \"Uploader\") \\\n",
    "    .withColumnRenamed(\"age\", \"Age\") \\\n",
    "    .withColumnRenamed(\"category\", \"Category\") \\\n",
    "    .withColumnRenamed(\"length\", \"Length\") \\\n",
    "    .withColumnRenamed(\"views\", \"Views\") \\\n",
    "    .withColumnRenamed(\"rate\", \"Rating\") \\\n",
    "    .withColumnRenamed(\"ratings\", \"Ratings Count\") \\\n",
    "    .withColumnRenamed(\"comments\", \"Comments Count\") \\\n",
    "    .withColumnRenamed(\"related_ids\", \"Related Videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc371bf-d42d-4e25-815c-773427a5c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform validation checks\n",
    "def validate_data(df):\n",
    "    # Check if column count matches expected schema\n",
    "    if len(df.columns) != 10:\n",
    "        print(\"Validation failed: Incorrect number of columns.\")\n",
    "        return False\n",
    "\n",
    "    # Check data types for each column\n",
    "    expected_types = {\n",
    "        \"Video ID\": \"string\",\n",
    "        \"Uploader\": \"string\",\n",
    "        \"Age\": \"int\",\n",
    "        \"Category\": \"string\",\n",
    "        \"Length\": \"int\",\n",
    "        \"Views\": \"int\",\n",
    "        \"Rating\": \"double\",\n",
    "        \"Ratings Count\": \"int\",\n",
    "        \"Comments Count\": \"int\",\n",
    "        \"Related Videos\": \"string\"\n",
    "    }\n",
    "\n",
    "    for col_name, expected_type in expected_types.items():\n",
    "        actual_type = df.schema[col_name].dataType.simpleString()\n",
    "        if actual_type != expected_type:\n",
    "            print(f\"Validation failed: Column '{col_name}' expected type '{expected_type}', found '{actual_type}'.\")\n",
    "            return False\n",
    "\n",
    "    # Validation passed\n",
    "    print(\"Validation successful: Dataset format is correct.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82dc96-3fff-4945-a164-ab2d896ab170",
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_data(combined_df):\n",
    "    # Display first 5 records\n",
    "    print(\"Displaying the first 5 records:\")\n",
    "    combined_df.show(5, truncate=False)\n",
    "\n",
    "    # Convert `related_ids` array to a single string\n",
    "    combined_df = combined_df.withColumn(\"Related Videos\", F.expr(\"concat_ws(',', `Related Videos`)\"))\n",
    "\n",
    "    # Prompt user for confirmation\n",
    "    confirm = input(\"Do you want to overwrite the files in HDFS? (y/n): \")\n",
    "    \n",
    "    if confirm.lower() == 'y':\n",
    "        # Save as a tab-delimited text file on HDFS\n",
    "        combined_df.coalesce(1).write.mode(\"overwrite\").option(\"delimiter\", \"\\t\").csv(\"hdfs://localhost:9000/path/to/merged_data_txt\", header=True)\n",
    "\n",
    "        # Save as a standard CSV file on HDFS\n",
    "        combined_df.coalesce(1).write.mode(\"overwrite\").csv(\"hdfs://localhost:9000/path/to/merged_data_csv\", header=True)\n",
    "\n",
    "        print(\"Files successfully saved to HDFS.\")\n",
    "    else:\n",
    "        print(\"Operation canceled. Files were not saved.\")\n",
    "else:\n",
    "    print(\"Dataset validation failed. Files will not be saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3537431-cadf-4387-be72-4cb54cf91040",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92d7cc-7894-48c2-96ff-7a335b4b75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ff8b3-b550-47e3-8de3-7acffe31d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_path = \"/hdfs/path/to/merged_data_csv/\"\n",
    "cmd = f\"hdfs dfs -cat {hdfs_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4bd039-a6cc-4052-9940-ec3ce5dbda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(cmd, shell=True, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd862e37-1d5f-4856-b34e-33e19dbbea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = StringIO(result.stdout)\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d9fc6-49e3-41e3-9257-450f998b9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Related Videos'] = df['Related Videos'].fillna(\"\").apply(lambda x: x.split(',') if x else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e40ef-8aa3-4581-8377-61632930b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\"Age\", \"Length\", \"Views\", \"Rating\", \"Ratings Count\", \"Comments Count\"]\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13430f1a-33d4-4127-93df-db299698eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cc253-20db-4e44-a808-d0ffab6cb0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/loacl/path/to/formatted_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce182544-603c-485a-b291-1118a07da6a7",
   "metadata": {},
   "source": [
    "#### 2. Script for formatting and transforming formatted_data.csv\n",
    "##### Upload to hdfs using the following command : hdfs dfs -copyFromLocal /path/to/formatted_data.csv /hdfs_directory/path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd9394-b970-4754-ba03-f178c5a0b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, explode, split, trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b02b5a-e065-4c75-9a4d-c18759a80bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/local/path/to/youtube.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beda07f-b4fe-4b4f-9160-1893f71da4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17300683-e0fc-4d6c-89f8-304e8b668ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc16ddf-ff83-4e1f-8eef-fa8ea20dd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"YouTube Data Cleaning\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e6600-d363-4d0d-a5ba-1c48de7c393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/hdfs/path/formatted_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac50477-9c01-4c33-92d9-0d150ce42259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2966dfb-ea34-42f8-bc1d-b33b262f92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.withColumn(\"Related Videos\", regexp_replace(df[\"Related Videos\"], \"[\\\\[\\\\]']\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2385e7-7488-4d49-b335-b2d9bb51071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_cleaned.withColumn(\"Related Videos\", explode(split(trim(df_cleaned[\"Related Videos\"]), \",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec728c-71c1-4332-b8ca-ff99b372e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.select(\"Video ID\", \"Uploader\", \"Age\", \"Category\", \"Length\", \"Views\", \"Rating\", \"Ratings Count\", \"Comments Count\", \"Related Videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a10d85-8988-408c-8b5f-1d4ea31a5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55396546-576e-435f-a2c7-4d410c58b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_header.write.csv(\"hdfs://localhost:9000/hdfs/path/cleaned_youtube_data\", \n",
    "                        header=False,  \n",
    "                        mode=\"overwrite\", \n",
    "                        sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafb300-6a67-46e1-a82a-87da111383b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab839803-6983-40c5-b322-58e6e3d13d41",
   "metadata": {},
   "source": [
    "#### 3. Hive to merge the flattened dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd12d2-66de-4248-ab8c-f7f99d698ac1",
   "metadata": {},
   "source": [
    "##### Run the following on Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8422488a-3a16-4e84-8a1f-0e70d48ea5c3",
   "metadata": {},
   "source": [
    "CREATE EXTERNAL TABLE youtube_data (\n",
    "    video_id STRING,\n",
    "    uploader STRING,\n",
    "    age FLOAT,\n",
    "    category STRING,\n",
    "    length FLOAT,\n",
    "    views FLOAT,\n",
    "    rating FLOAT,\n",
    "    ratings_count FLOAT,\n",
    "    comments_count FLOAT,\n",
    "    related_videos STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY '\\t'\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/hdfs/path/cleaned_youtube_data/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515956c-6596-4f20-9ead-8c4a66aab8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM youtube_data LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a721b07-9452-412a-9cd4-c730f35a8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE merged_youtube_data (\n",
    "    video_id STRING,\n",
    "    uploader STRING,\n",
    "    age FLOAT,\n",
    "    category STRING,\n",
    "    length FLOAT,\n",
    "    views FLOAT,\n",
    "    rating FLOAT,\n",
    "    ratings_count FLOAT,\n",
    "    comments_count FLOAT,\n",
    "    related_videos STRING\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036b08a-1e12-4722-806e-7922658ec296",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT INTO TABLE merged_youtube_data\n",
    "SELECT \n",
    "    video_id, \n",
    "    uploader, \n",
    "    age, \n",
    "    category, \n",
    "    length, \n",
    "    views, \n",
    "    rating, \n",
    "    ratings_count, \n",
    "    comments_count, \n",
    "    CONCAT_WS(',', COLLECT_LIST(related_videos)) AS related_videos\n",
    "FROM \n",
    "    youtube_data\n",
    "GROUP BY \n",
    "    video_id, \n",
    "    uploader, \n",
    "    age, \n",
    "    category, \n",
    "    length, \n",
    "    views, \n",
    "    rating, \n",
    "    ratings_count, \n",
    "    comments_count;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701cf231-212a-461e-8569-f6ab8ec3afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT OVERWRITE DIRECTORY '/hdfs/path/Hive/merged_youtube_data'\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY '\\t'  -- Use tab as the field separator\n",
    "LINES TERMINATED BY '\\n'     -- Use newline for line termination\n",
    "SELECT \n",
    "    video_id, \n",
    "    uploader, \n",
    "    age, \n",
    "    category, \n",
    "    length, \n",
    "    views, \n",
    "    rating, \n",
    "    ratings_count, \n",
    "    comments_count, \n",
    "    CONCAT_WS(',', COLLECT_LIST(related_videos)) AS related_videos -- Keep comma for related video IDs\n",
    "FROM \n",
    "    merged_youtube_data\n",
    "GROUP BY \n",
    "    video_id, \n",
    "    uploader, \n",
    "    age, \n",
    "    category, \n",
    "    length, \n",
    "    views, \n",
    "    rating, \n",
    "    ratings_count, \n",
    "    comments_count;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
